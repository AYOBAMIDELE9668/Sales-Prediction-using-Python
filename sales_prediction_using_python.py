# -*- coding: utf-8 -*-
"""Sales Prediction using Python

Automatically generated by Colab.

Original file is located at
    https://colab.research.google.com/drive/1kdxYyfKpzYHljRfeZXtCpfl31EABoga3
"""

import pandas as pd
import numpy as np
import matplotlib.pyplot as plt
import seaborn as sns
from sklearn.model_selection import train_test_split
from sklearn.linear_model import LinearRegression
from sklearn.metrics import mean_squared_error, r2_score

df = pd.read_csv('Advertising.csv')

print(df.head(5))

print(df.info())

print(df.describe())

print(df.isnull().sum())

# Visualize the distribution of features
plt.figure(figsize=(12, 6))
for i, column in enumerate(['TV', 'Radio', 'Newspaper', 'Sales'], 1):
    plt.subplot(2, 2, i)
    sns.histplot(df[column], kde=True, bins=20)
    plt.title(f'Distribution of {column}')
plt.tight_layout()
plt.show()

# Correlation matrix
correlation_matrix = df.corr()
sns.heatmap(correlation_matrix, annot=True, cmap='coolwarm')
plt.title('Correlation Matrix')
plt.show()

# Pairplot to visualize relationships between variables
sns.pairplot(df)
plt.show()

df.drop(columns=['Unnamed: 0'], inplace=True, errors='ignore')

# Define features (X) and target variable (y)
X = df[['TV', 'Radio', 'Newspaper']]
y = df['Sales']

# Split the data into training and testing sets (80% train, 20% test)
X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)

# Check the shapes of the datasets
print("Training set shape:", X_train.shape, y_train.shape)
print("Testing set shape:", X_test.shape, y_test.shape)

model = LinearRegression()

# Train the model on the training data
model.fit(X_train, y_train)

# Print the coefficients and intercept
print("Coefficients:", model.coef_)
print("Intercept:", model.intercept_)

y_pred = model.predict(X_test)

# Calculate evaluation metrics
mse = mean_squared_error(y_test, y_pred)
rmse = np.sqrt(mse)
r2 = r2_score(y_test, y_pred)

# Print the evaluation metrics
print("Mean Squared Error (MSE):", mse)
print("Root Mean Squared Error (RMSE):", rmse)
print("R-squared (R2):", r2)

# Visualize actual vs predicted values
plt.figure(figsize=(8, 6))
plt.scatter(y_test, y_pred, alpha=0.7)
plt.plot([y_test.min(), y_test.max()], [y_test.min(), y_test.max()], color='red', linestyle='--')
plt.xlabel('Actual Sales')
plt.ylabel('Predicted Sales')
plt.title('Actual vs Predicted Sales')
plt.show()

# Create a DataFrame to display feature importance
feature_importance = pd.DataFrame({
    'Feature': X.columns,
    'Coefficient': model.coef_
}).sort_values(by='Coefficient', ascending=False)

print(feature_importance)

import joblib

# Save the trained model to a file
joblib.dump(model, 'sales_prediction_model.pkl')

# To load the model later:
# loaded_model = joblib.load('sales_prediction_model.pkl')

# Example: Predict sales for new advertising budget
new_data = pd.DataFrame({
    'TV': [200],
    'Radio': [50],
    'Newspaper': [30]
})

predicted_sales = model.predict(new_data)
print("Predicted Sales:", predicted_sales[0])